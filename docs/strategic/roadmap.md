# GenesisGraph Roadmap

**Last Updated:** 2025-11-21
**Current Version:** v0.3.0
**Target Version:** v1.0 (Production-Ready)

---

## Vision

**GenesisGraph v1.0 will be the universal standard for verifiable process provenance**, enabling organizations to prove how things were made while protecting trade secrets through selective disclosure.

**Key Differentiators:**
- First provenance standard solving the IP-vs-compliance dilemma
- AI agent accountability and multi-agent governance
- Production-ready for regulated industries (aerospace, pharma, AI safety)
- Self-sustaining ecosystem with governance safeguards

---

## Current State: v0.3.0 (November 2025)

### âœ… Completed Features

**Core Functionality:**
- âœ… Three-level selective disclosure (A/B/C)
- âœ… Schema validation with genesisgraph-core-v0.1.yaml
- âœ… Entity/Operation/Tool validation
- âœ… Cryptographic signatures (Ed25519)
- âœ… Hash verification (SHA256, SHA512, Blake3)
- âœ… CLI tool (`gg` command)

**Advanced Features:**
- âœ… DID resolution (did:key, did:web, did:ion, did:ethr)
- âœ… Certificate Transparency log integration (RFC 6962)
- âœ… Selective Disclosure JWT (SD-JWT)
- âœ… BBS+ signatures for privacy
- âœ… Zero-knowledge proof templates
- âœ… Profile validators (AI Basic, CAM)
- âœ… ISO 9001 and FDA 21 CFR 11 compliance validators

**SDKs:**
- âœ… Python SDK (published to PyPI)
- âœ… JavaScript/TypeScript SDK (ready for npm)

**Testing & Quality:**
- âœ… 666+ comprehensive tests
- âœ… ~63% test coverage
- âœ… CI/CD with GitHub Actions (Python 3.8-3.12)
- âœ… Pre-commit hooks configured
- âœ… Performance optimizations (2-3x faster with pre-compiled regex)

**Documentation:**
- âœ… Complete specification (24,317 lines)
- âœ… Comprehensive guides (DID, transparency logs, ZKP, selective disclosure)
- âœ… 13 YAML examples
- âœ… QUICKSTART, USE_CASES, FAQ, Strategic context

**Project Health:** 8/10 - Excellent foundation, clear improvement path

---

## Gaps Analysis: What's Missing for v1.0

Based on comprehensive analysis documented in [CRITICAL_GAPS_ANALYSIS.md](CRITICAL_GAPS_ANALYSIS.md) and [IMPROVEMENT_PLAN.md](IMPROVEMENT_PLAN.md):

### ğŸ”´ Critical Gaps (Block Enterprise Adoption)

1. **Formal Threat Model** - No documented security guarantees for regulators
2. **Delegation & Authorization** - Can't prove agents were authorized to act
3. **Lifecycle & Revocation** - No temporal validation or revocation mechanism
4. **AI Agent Provenance** - No support for agent reasoning traces, tool delegation
5. **Governance Foundation** - Risk of capture by large actors

### ğŸŸ¡ High Priority Gaps (Required for Ecosystem Maturity)

6. **Registry Infrastructure** - No canonical tool/profile registry
7. **Human-Oriented UX** - Too technical for non-cryptographers
8. **Formal Semantics** - Operation chains lack mathematical formalization
9. **Test Coverage** - 63% â†’ need 90%+ for production
10. **Dispute Resolution** - No mechanism for conflicting claims

### ğŸŸ¢ Strategic Gaps (Long-term Positioning)

11. **Economic Model** - No sustainability/incentive structure
12. **API Documentation** - No hosted docs site
13. **Performance** - Unknown scaling characteristics
14. **Community** - No external contributors yet

---

## Roadmap: Phases to v1.0

### Phase 0.4: Foundation & Quality (4-6 weeks)
**Goal:** Production-grade code quality and developer experience
**Priority:** Infrastructure that enables faster development

#### Work Items
- [ ] **Increase test coverage to 90%+** (12-16 hours)
  - Add CLI tests (currently 0% coverage)
  - Add edge case tests (unicode, large files, circular dependencies)
  - Add integration tests for end-to-end workflows
  - Target: All modules â‰¥ 85% coverage

- [ ] **Create API documentation site** (6-8 hours)
  - Set up MkDocs with Material theme
  - Auto-generate API reference from docstrings
  - Deploy to GitHub Pages
  - Migrate existing guides to docs site

- [ ] **Tighten type checking** (4-6 hours)
  - Enable strict mypy configuration
  - Fix all type errors
  - Remove `continue-on-error` from CI
  - 100% type coverage for public API

- [ ] **Add architecture documentation** (4-6 hours)
  - System architecture diagram
  - Validation flow diagram
  - Class relationship diagram
  - Design decisions documentation

- [ ] **Create troubleshooting guide** (2-3 hours)
  - Document common errors and solutions
  - Platform-specific issues (Windows, macOS, Linux)
  - Debug mode instructions

**Success Metrics:**
- Test coverage â‰¥ 90%
- API docs live at docs.genesisgraph.dev
- Mypy passes with strict mode
- Zero critical code quality issues

**Milestone:** v0.4.0 release

---

### Phase 0.5: Security & Lifecycle (5-7 weeks)
**Goal:** Production-ready security for regulated industries
**Priority:** ğŸ”´ CRITICAL - Blocks regulatory adoption

#### Work Items
- [ ] **Create formal threat model** (2-3 weeks)
  - Document adversary classes (malicious tools, nation-states, AI agents, supply chain attackers)
  - Define trust assumptions (TEE roots, transparency log operators, DID registries)
  - Security goals (integrity, auditability, privacy, non-repudiation)
  - Attack-defense matrix
  - Independent security audit

- [ ] **Define security levels** (1 week)
  - GG-SEC-1: Basic (hashes + timestamps)
  - GG-SEC-2: Signed (digital signatures + DIDs)
  - GG-SEC-3: Verifiable (transparency logs + multisig)
  - GG-SEC-4: Maximum (TEE + ZK proofs + Byzantine fault tolerance)
  - Document guarantees for each level

- [ ] **Implement lifecycle & revocation model** (3-4 weeks)
  - Add lifecycle metadata to entities (created_at, valid_from, valid_until, revoked_at)
  - Add revocation endpoints to attestations
  - Implement tool version lineage tracking
  - Add temporal validation (`verify_at_time` parameter)
  - Create `gg verify --at-time` CLI command
  - Historical revocation list support

- [ ] **Create SECURITY.md** (2-3 hours)
  - Vulnerability reporting process
  - Security considerations for each disclosure level
  - Threat model summary
  - Cryptographic assumptions
  - Best practices for users

**Success Metrics:**
- THREAT_MODEL.md reviewed by 3+ security experts
- Security levels defined and documented
- Revocation mechanism working (test: revoke tool, verify fails)
- SECURITY.md follows GitHub security advisory format

**Dependencies:** Independent security auditors, threat modeling expertise

**Milestone:** v0.5.0 release - "Production Security"

---

### Phase 0.6: Delegation & Authorization (4-6 weeks)
**Goal:** Enable AI agent ecosystems with provable authorization
**Priority:** ğŸ”´ CRITICAL - Required for AI governance

**Strategic Value:** This is THE killer feature - no other provenance system has this.

#### Work Items
- [ ] **Extend schema with delegation objects** (1 week)
  - Add `authorization` field to operations
  - Add `delegation_chain` structure
  - Add `policy_evaluation` trace
  - Schema version bump to v0.2.0

- [ ] **Implement delegation standards support** (2-3 weeks)
  - ZCAP-LD (W3C Authorization Capabilities)
  - Macaroons (bearer tokens with caveats)
  - OAuth 2.0 integration
  - Verifiable Credentials for permissions

- [ ] **Create policy engine integration** (1-2 weeks)
  - OPA (Open Policy Agent) evaluation traces
  - Cedar (AWS policy language) support
  - Policy decision recording
  - Attestable policy compliance

- [ ] **Create `gg-delegation-v1` profile** (1 week)
  - Required fields for delegation-aware provenance
  - Validation rules for authorization chains
  - Revocation checking requirements
  - Example workflows

- [ ] **Documentation & examples** (1 week)
  - Delegation guide (docs/DELEGATION_GUIDE.md)
  - Medical AI delegation example
  - Manufacturing certification delegation
  - Multi-agent coordination example

**Success Metrics:**
- Authorization chains validated correctly
- Policy evaluation traces captured
- Working example: AI agent with HIPAA delegation
- Integration with at least 2 policy engines (OPA, Cedar)

**Dependencies:** Policy engine expertise, Verifiable Credentials knowledge

**Milestone:** v0.6.0 release - "AI Agent Authorization"

---

### Phase 0.7: AI Agent Provenance (8-12 weeks)
**Goal:** Become THE standard for AI agent governance
**Priority:** ğŸ”´ CRITICAL - Strategic positioning

**Strategic Value:** Positions GenesisGraph for AI safety/governance market

#### Work Items
- [ ] **Create GG-Agent-v1 profile specification** (2-3 weeks)
  - Agent identity model (did:agent)
  - Agent capabilities declaration
  - Agent delegation constraints
  - Memory/state checkpointing model

- [ ] **Implement agent operation types** (3-4 weeks)
  - `agent_reasoning_step` - Chain-of-thought traces
  - `agent_tool_invocation` - Tool use with delegation
  - `agent_memory_update` - State transitions
  - `agent_multi_turn_conversation` - Session provenance

- [ ] **Selective disclosure for reasoning** (2-3 weeks)
  - Redacted reasoning traces (hide proprietary prompts)
  - Policy claim verification without revealing reasoning
  - Sealed subgraphs for agent internals
  - Merkle commitments for step counts

- [ ] **Safety/alignment attestations** (1-2 weeks)
  - Refusal behavior certification
  - Jailbreak resistance testing
  - Goal alignment verification
  - Model card integration

- [ ] **Multi-agent coordination primitives** (1-2 weeks)
  - Agent-to-agent delegation
  - Shared state provenance
  - Coordination protocol traces

- [ ] **Documentation & examples** (2 weeks)
  - AI Agent Provenance Guide (docs/AI_AGENT_GUIDE.md)
  - Example: Claude agent with tool use
  - Example: Multi-agent research workflow
  - Example: AI safety certification

**Success Metrics:**
- Working agent provenance for Claude/GPT-4 workflows
- Reasoning traces with selective disclosure
- Safety attestations verifiable
- Published case study: "Auditable AI Agents with GenesisGraph"

**Dependencies:** Partnership with AI lab (Anthropic, OpenAI) for pilot

**Milestone:** v0.7.0 release - "AI Agent Governance"

---

### Phase 0.8: Governance & Ecosystem (12-16 weeks)
**Goal:** Self-sustaining ecosystem with capture resistance
**Priority:** ğŸŸ¡ HIGH - Required for long-term sustainability

#### Work Items
- [ ] **Establish GenesisGraph Foundation** (4-6 weeks)
  - Legal entity formation (501c6 nonprofit)
  - Multi-stakeholder board (9 members: AI, manufacturing, science, government, civil society)
  - Anti-capture rules (no single entity >2 seats, <30% maintainers)
  - Term limits and rotation

- [ ] **Create registry infrastructure** (6-8 weeks)
  - Tool registry (Rekor-based transparency log)
  - Profile registry with governance
  - Schema registry with compatibility guarantees
  - DID registry for canonical identities
  - Deploy to registry.genesisgraph.dev

- [ ] **Define governance processes** (2-3 weeks)
  - Change control process (2/3 majority for breaking changes)
  - Dispute resolution (3-level escalation)
  - Certification program (3 tiers: Verified, Professional, Enterprise)
  - Trademark policy

- [ ] **Create funding model** (2-3 weeks)
  - Membership dues structure (Platinum $50k, Gold $25k, Silver $10k)
  - Grant applications (NSF, NIST, Sloan, Schmidt)
  - Registry hosting cost recovery
  - Certification program revenue

- [ ] **Compatibility certification** (2-3 weeks)
  - Conformance test suite
  - `gg certify-implementation` command
  - "GenesisGraph Compatible" badge program
  - Vendor certification process

**Success Metrics:**
- Foundation formed with initial board
- Registry live with â‰¥10 verified tools
- 3+ foundation members paying dues
- Governance documents published and approved

**Dependencies:** Legal counsel, founding members, funding

**Milestone:** v0.8.0 release - "Ecosystem Infrastructure"

---

### Phase 0.9: Human UX & Polish (6-8 weeks)
**Goal:** Accessible to non-cryptographers
**Priority:** ğŸŸ¡ HIGH - Drives adoption

#### Work Items
- [ ] **Create opinionated templates** (2-3 weeks)
  - `gg template create ai-inference-redacted`
  - `gg template create manufacturing-iso9001`
  - `gg template create science-reproducible`
  - `gg template create agent-delegation-audit`
  - 10+ common workflow templates

- [ ] **Interactive CLI wizard** (2-3 weeks)
  - `gg init` - Interactive setup
  - Profile selection wizard
  - Disclosure level preview
  - Best practices suggestions

- [ ] **Visual tools** (2-3 weeks)
  - Provenance graph renderer (graphviz/mermaid)
  - Compliance report generator (PDF)
  - Disclosure preview tool (`gg preview --persona auditor`)
  - Timeline visualization

- [ ] **Best-practice guides** (1-2 weeks)
  - HOW_TO_REDACT_SAFELY.md
  - MULTISIG_BEST_PRACTICES.md
  - SEALED_SUBGRAPH_TUTORIAL.md
  - TRANSPARENCY_LOG_SETUP.md

- [ ] **Video tutorials** (1-2 weeks)
  - 5-minute intro to GenesisGraph
  - Proving AI work without revealing prompts
  - Manufacturing compliance with IP protection
  - Multi-party attestations

**Success Metrics:**
- Non-technical users can create provenance in <10 minutes
- Template usage in 80%+ of new workflows
- Video tutorials with 1000+ views
- User feedback: "Easy to use" (8/10 average)

**Milestone:** v0.9.0 release - "Human-Friendly UX"

---

### Phase 1.0: Production Release (4-6 weeks)
**Goal:** Production-ready for mission-critical systems
**Priority:** ğŸ”´ CRITICAL - Market launch

#### Work Items
- [ ] **Final security audit** (2-3 weeks)
  - Independent third-party audit
  - Penetration testing
  - Cryptographic review
  - Fix all findings

- [ ] **Performance optimization** (1-2 weeks)
  - Benchmark large workflows (1000+ entities)
  - Parallel hash verification
  - Caching for repeated validations
  - Memory profiling and optimization

- [ ] **Production documentation** (1-2 weeks)
  - Migration guide from v0.x
  - Production deployment guide
  - SLA and support policy
  - Enterprise integration guide

- [ ] **Ecosystem partnerships** (2-3 weeks)
  - Partnership with 1+ AI lab
  - Partnership with 1+ aerospace/manufacturing company
  - Partnership with 1+ research institution
  - Case studies published

- [ ] **Release preparation** (1 week)
  - Version 1.0.0 changelog
  - Press release
  - Blog post series
  - Community announcements

**Success Metrics:**
- Security audit with zero critical findings
- 3+ production deployments in different industries
- 100+ GitHub stars
- 10+ ecosystem partners

**Milestone:** v1.0.0 release - "Production Ready"

---

## Priority Framework

All work is categorized using this framework:

### ğŸ”´ P0 - Critical
**Definition:** Blocks enterprise adoption, creates security vulnerabilities, or prevents core use cases

**Examples:**
- Threat model documentation
- Delegation framework
- AI agent provenance
- Security audit

**Timeline:** Next 6 months (v0.5-v0.7)

### ğŸŸ¡ P1 - High
**Definition:** Required for ecosystem maturity, significant UX impact, or production readiness

**Examples:**
- Test coverage 90%+
- Registry infrastructure
- Human-oriented UX
- Governance foundation

**Timeline:** 6-12 months (v0.4, v0.8-v0.9)

### ğŸŸ¢ P2 - Medium
**Definition:** Nice-to-have features, optimizations, or long-term strategic positioning

**Examples:**
- Dispute resolution
- Economic model
- Performance optimization
- Video tutorials

**Timeline:** 12-18 months (v0.9-v1.0)

### âšª P3 - Low
**Definition:** Future enhancements, experimental features, or non-critical improvements

**Examples:**
- Additional DID methods
- Exotic hash algorithms
- Advanced ZKP templates
- Multi-language SDKs

**Timeline:** Post v1.0 (v1.1+)

---

## Next 90 Days: Focus Areas

### Immediate (Weeks 1-4) - v0.4.0 Sprint
**Theme:** Foundation & Quality

**Primary Goals:**
1. Increase test coverage to 90%+ (MUST DO)
2. Launch API documentation site
3. Enable strict type checking

**Why:** These are prerequisites for confident development of complex features (delegation, agents). Technical debt now = slower later.

**Owner:** Core team
**Dependencies:** None
**Risk:** Low

---

### Near-term (Weeks 5-10) - v0.5.0 Sprint
**Theme:** Security & Trust

**Primary Goals:**
1. Complete formal threat model with independent review
2. Implement lifecycle & revocation framework
3. Define security levels (GG-SEC-1 through GG-SEC-4)

**Why:** Regulators and enterprise security teams need documented guarantees. This is table stakes for aerospace, pharma, government adoption.

**Owner:** Core team + security consultant
**Dependencies:** Security expert review
**Risk:** Medium (requires expertise)

---

### Mid-term (Weeks 11-20) - v0.6.0 Sprint
**Theme:** AI Agent Authorization

**Primary Goals:**
1. Implement delegation & authorization framework
2. Create policy engine integrations (OPA, Cedar)
3. Build working demo: AI agent with HIPAA delegation

**Why:** This is GenesisGraph's unique value prop. First-mover advantage in AI agent governance.

**Owner:** Core team + AI partner
**Dependencies:** Policy engine expertise, AI lab partnership
**Risk:** High (novel territory, requires partnerships)

---

## Milestones & Timeline

```
v0.3.0 â”â”â”â”â”â”â”“
(Nov 2025)   â”ƒ
             â”ƒ
v0.4.0 â”â”â”â”â”â”â”« (Jan 2026) - Foundation & Quality
             â”ƒ   - 90% test coverage
             â”ƒ   - API docs live
             â”ƒ   - Strict typing
             â”ƒ
v0.5.0 â”â”â”â”â”â”â”« (Mar 2026) - Security & Lifecycle
             â”ƒ   - Threat model
             â”ƒ   - Revocation framework
             â”ƒ   - Security audit
             â”ƒ
v0.6.0 â”â”â”â”â”â”â”« (May 2026) - Delegation & Authorization
             â”ƒ   - Authorization chains
             â”ƒ   - Policy engines
             â”ƒ   - Agent delegation
             â”ƒ
v0.7.0 â”â”â”â”â”â”â”« (Aug 2026) - AI Agent Provenance
             â”ƒ   - Agent reasoning traces
             â”ƒ   - Tool delegation
             â”ƒ   - Safety attestations
             â”ƒ
v0.8.0 â”â”â”â”â”â”â”« (Nov 2026) - Governance & Ecosystem
             â”ƒ   - Foundation formed
             â”ƒ   - Registry live
             â”ƒ   - Certification program
             â”ƒ
v0.9.0 â”â”â”â”â”â”â”« (Jan 2027) - Human UX & Polish
             â”ƒ   - Templates & wizards
             â”ƒ   - Visual tools
             â”ƒ   - Video tutorials
             â”ƒ
v1.0.0 â”â”â”â”â”â”â”› (Mar 2027) - Production Release
             ğŸ¯  - Security audit complete
                 - 3+ production deployments
                 - Ecosystem partnerships
```

**Total Timeline:** ~16 months (Nov 2025 - Mar 2027)

---

## Decision Framework

When evaluating new features or changes, use this framework:

### 1. Strategic Alignment
- Does this advance AI agent governance? (core differentiator)
- Does this solve IP-vs-compliance dilemma? (core value prop)
- Does this enable regulated industry adoption? (target market)

### 2. Impact Assessment
- Who benefits? (developers, enterprises, regulators, end-users)
- What's the reach? (niche vs broad applicability)
- What's the timeline? (immediate vs long-term)

### 3. Effort vs Value
- **High Value, Low Effort** â†’ Do immediately (P0)
- **High Value, High Effort** â†’ Plan carefully, execute next (P0-P1)
- **Low Value, Low Effort** â†’ Consider if spare capacity (P2-P3)
- **Low Value, High Effort** â†’ Defer or reject

### 4. Dependencies
- Does this block other work? (critical path)
- Does this require external expertise? (partnership risk)
- Does this require infrastructure? (registry, foundation)

---

## How to Contribute

### For Core Features (Delegation, Agents, Security)
1. Review relevant gap analysis section in CRITICAL_GAPS_ANALYSIS.md
2. Comment on tracking issue (create if doesn't exist)
3. Propose design in GitHub Discussion
4. Get approval from core team before implementation
5. Follow development process below

### For Bug Fixes and Incremental Improvements
1. Check existing issues and roadmap
2. Create issue if doesn't exist
3. Reference roadmap phase if applicable
4. Submit PR with tests
5. Link to issue in PR description

### Development Process
1. Fork repository
2. Create feature branch from `main`
3. Write tests first (TDD approach)
4. Implement feature
5. Ensure all tests pass (90%+ coverage)
6. Update documentation
7. Submit PR with clear description
8. Address review feedback
9. Maintain PR until merged

### Documentation Contributions
1. All new features require documentation
2. API changes require docstring updates
3. User-facing changes require guide updates
4. Examples highly valued

---

## Success Criteria for v1.0

### Technical Excellence
- [ ] Test coverage â‰¥ 90% across all modules
- [ ] Security audit with zero critical findings
- [ ] API documentation complete and hosted
- [ ] Performance benchmarks meet targets (<100ms validation for typical workflows)
- [ ] Zero known security vulnerabilities

### Feature Completeness
- [ ] Threat model documented and reviewed
- [ ] Delegation & authorization working
- [ ] Lifecycle & revocation implemented
- [ ] AI agent provenance operational
- [ ] Registry infrastructure live
- [ ] Human-friendly UX (templates, wizards, visualizations)

### Ecosystem Health
- [ ] GenesisGraph Foundation established
- [ ] 3+ foundation members with paid dues
- [ ] Registry with â‰¥10 verified tools
- [ ] 3+ production deployments (different industries)
- [ ] 10+ ecosystem partners

### Community Adoption
- [ ] 500+ GitHub stars
- [ ] 20+ external contributors
- [ ] 100+ community issues/discussions
- [ ] 5+ blog posts/case studies
- [ ] 1000+ PyPI downloads/month

### Market Validation
- [ ] Partnership with major AI lab (Anthropic, OpenAI, Google)
- [ ] Partnership with aerospace/manufacturing company
- [ ] Partnership with research institution
- [ ] Featured in industry publication
- [ ] Speaking at major conference (NeurIPS, ICML, manufacturing summit)

---

## FAQ

### Why so many phases?
Complex features (delegation, agents, governance) require careful design. Rushing leads to technical debt and poor UX. Incremental releases enable feedback and course correction.

### Why prioritize AI agents over manufacturing?
AI governance is a greenfield opportunity where GenesisGraph can become the standard. Manufacturing has existing systems (harder to displace). We'll serve both, but AI agents are the wedge.

### Can we skip security audit?
No. Enterprise adoption requires documented security guarantees. The audit finds issues now before they become breaches later.

### What if we can't form a foundation?
Governance can start as informal steering committee. Foundation formalizes anti-capture rules and enables funding. Start informal, formalize when ecosystem grows.

### How do we fund development?
**Phase 0-1:** Open source contributions, grant funding (NSF, NIST)
**Phase 1+:** Foundation membership dues, certification program, registry hosting
**Long-term:** Sustainable economic flywheel (see CRITICAL_GAPS_ANALYSIS.md Gap #10)

---

## Related Documents

- **[CRITICAL_GAPS_ANALYSIS.md](CRITICAL_GAPS_ANALYSIS.md)** - Strategic analysis of 10 gaps for v1.0
- **[IMPROVEMENT_PLAN.md](IMPROVEMENT_PLAN.md)** - Tactical implementation details (being updated for v0.3.0+ reality)
- **[STRATEGIC_CONTEXT.md](STRATEGIC_CONTEXT.md)** - Why this matters, market positioning, 5-year vision
- **[spec/MAIN_SPEC.md](spec/MAIN_SPEC.md)** - Technical specification
- **[CHANGELOG.md](CHANGELOG.md)** - Version history and release notes

---

## Contact & Governance

**Maintainer:** Scott Sen
**Repository:** https://github.com/scottsen/genesisgraph
**Discussions:** https://github.com/scottsen/genesisgraph/discussions
**Issues:** https://github.com/scottsen/genesisgraph/issues

**Governance Model (current):** Benevolent dictator (transitioning to multi-stakeholder by v0.8.0)

---

**This is a living document. Updates are made quarterly or after major milestones.**

**Next Review:** After v0.4.0 release (target: January 2026)
